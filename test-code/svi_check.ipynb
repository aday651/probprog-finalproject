{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "import logging\n",
    "from torch.distributions import constraints\n",
    "from bitcoin import BitcoinOTC\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "# Validation checks\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "c:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\numpy\\core\\_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "c:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\numpy\\core\\_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "data = BitcoinOTC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_args = {'sample_str': 'random-walk', 'sample_args': {'start_num': 5, 'walk_length': 50}}\n",
    "sample_args = {'sample_str': 'p-sampling', 'sample_args': {'sample_prob': 0.05}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node_ind': tensor([   0,    1,    2,  ..., 5982, 5992, 5996]), 'edge_ind': tensor([   54,    98,   111,  ..., 35508, 35557, 35585]), 'edge_list': tensor([[  30,   54,    3,  ..., 3450, 1017, 1952],\n",
      "        [   0,    6,   65,  ..., 5982,  904, 5654]])}\n"
     ]
    }
   ],
   "source": [
    "print(data.subsample(**sample_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_scale = 1.0\n",
    "obs_scale = 1.0\n",
    "embed_dim = 2\n",
    "\n",
    "def guide(data, sample_args):\n",
    "    r\"\"\"Defines a variational family to use to fit an approximate posterior\n",
    "    distribution for the probability model defined in model.\n",
    "    \"\"\"\n",
    "    # Parameters governing the priors on the embedding vectors\n",
    "    omega_loc = pyro.param('omega_loc',\n",
    "                           torch.randn(embed_dim, data.num_nodes))\n",
    "    omega_scale = pyro.param('omega_scale', torch.tensor(1.0),\n",
    "                             constraint=constraints.positive)\n",
    "\n",
    "    # Parameters governing the prior for the linear regression\n",
    "    beta_loc = pyro.param('beta_loc', 0.5*torch.randn(embed_dim))\n",
    "    beta_scale = pyro.param('beta_scale', torch.tensor(1.0),\n",
    "                            constraint=constraints.positive)\n",
    "    mu_loc = pyro.param('mu_loc', torch.randn(1))\n",
    "    mu_scale = pyro.param('mu_scale', torch.tensor(1.0),\n",
    "                          constraint=constraints.positive)\n",
    "\n",
    "    # Sample the coefficient vector and intercept for linear regression\n",
    "    beta = pyro.sample('beta', dist.MultivariateNormal(\n",
    "        loc=beta_loc, covariance_matrix=(beta_scale**2)*torch.eye(embed_dim)\n",
    "    ))\n",
    "    mu = pyro.sample('mu', dist.Normal(mu_loc, mu_scale))\n",
    "\n",
    "    # Subsample vertices now in the guide\n",
    "    subsample = data.subsample(**sample_args)\n",
    "\n",
    "    # (Sub)sample embedding vectors\n",
    "    for i in pyro.plate('nodes', size=data.num_nodes,\n",
    "                        subsample=subsample['node_ind']):\n",
    "        pyro.sample('omega_{}'.format(i),\n",
    "                    dist.MultivariateNormal(\n",
    "            loc=omega_loc[:, i],\n",
    "            covariance_matrix=(omega_scale**2)*torch.eye(embed_dim)\n",
    "        )\n",
    "        )\n",
    "\n",
    "    # Define plate for the edge subsampling to pass to model object\n",
    "    with pyro.plate('edges', size=data.num_edges,\n",
    "                    subsample=subsample['edge_ind']):\n",
    "        # Note: we use pyro plate here as we need to keep the subsampling\n",
    "        # persistent in both our model and guide functions, we so we\n",
    "        # define an empty plate here just so we can use the same call\n",
    "        # in the model.\n",
    "        pass\n",
    "\n",
    "    return beta, mu\n",
    "\n",
    "\n",
    "def model(data, sample_args):\n",
    "    r\"\"\"Defines a probabilistic model for the observed network data.\"\"\"\n",
    "    # Define priors on the regression coefficients\n",
    "    mu = pyro.sample('mu', dist.Normal(torch.tensor(0.0), torch.tensor(2.0)))\n",
    "    beta = pyro.sample('beta', dist.MultivariateNormal(\n",
    "        loc=torch.zeros(embed_dim), covariance_matrix=4*torch.eye(embed_dim)\n",
    "    ))\n",
    "\n",
    "    # Define prior on the embedding vectors, do subsampling for the\n",
    "    # embedding vector and then the likelihood term for the observed nodes\n",
    "    omega = [0 for i in range(data.num_nodes)]\n",
    "\n",
    "    for i in pyro.plate('nodes', size=data.num_nodes):\n",
    "        # Embedding vectors\n",
    "        omega[i] = pyro.sample('omega_{}'.format(i), dist.MultivariateNormal(\n",
    "            loc=torch.zeros(embed_dim),\n",
    "            covariance_matrix=(omega_scale**2)*torch.eye(embed_dim)\n",
    "        ))\n",
    "\n",
    "        # Draw Bernoulli, with or without data depending on if it is observed\n",
    "        logit = mu + torch.dot(beta, omega[i])\n",
    "        if i in data.nodes_train:\n",
    "            pyro.sample('trust_{}'.format(i), dist.Bernoulli(logits=logit), obs=data.gt[i])\n",
    "\n",
    "    # Draw terms corresponding to the edges\n",
    "    for i in pyro.plate('edges', size=data.num_edges):\n",
    "        logit_rating = 0.05 + 0.9*data.edge_weight[i]\n",
    "        logit_rating = torch.log((logit_rating)/(1 - logit_rating))\n",
    "        emip = torch.dot(omega[data.edge_index[0, i]],\n",
    "                         omega[data.edge_index[1, i]])\n",
    "        pyro.sample('a_{}'.format(i), dist.Normal(emip, obs_scale), obs=logit_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Time to create SVI object: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "svi = SVI(model,\n",
    "          guide,\n",
    "          optim.Adam({\"lr\": .05}),\n",
    "          loss=Trace_ELBO())\n",
    "\n",
    "t1 = time.time()\n",
    "logging.info(\"Time to create SVI object: {}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8c29a66e0cb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0melbo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Elbo loss: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melbo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\pyro\\infer\\svi.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# get loss and compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[1;32mc:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\pyro\\infer\\trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurrogate_loss_particle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'requires_grad'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0msurrogate_loss_particle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[0mwarn_if_nan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \"\"\"\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\andrew\\anaconda3\\envs\\ppp\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "num_iters = 200\n",
    "\n",
    "for i in range(num_iters):\n",
    "    elbo = svi.step(data, sample_args)\n",
    "    if i % 5 == 0:\n",
    "        logging.info(\"Elbo loss: {}\".format(elbo))\n",
    "        if (i > 0):\n",
    "            t2 = time.time()\n",
    "            logging.info(\"Time to run 5 gradient steps of SVI: {}\".format(t2-t1))\n",
    "            t1 = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
